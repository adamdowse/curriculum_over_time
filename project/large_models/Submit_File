#Condor submit file

universe = docker
docker_image = registry.eps.surrey.ac.uk/adamsdocker:38355

executable = /usr/bin/python3
arguments = $ENV(PWD)/RunTest.py --max_epochs $(max_epochs) --learning_rate $(learning_rate) --batch_size $(batch_size) --scoring_function $(scoring_function) --pacing_function $(pacing_function) --fill_function $(fill_function) --dataset $(dataset) --dataset_size $(dataset_size) --test_dataset_size $(test_dataset_size) --dataset_similarity $(dataset_similarity) --data_path $(data_path) --db_path $(db_path) --save_model_path $(save_model_path) --early_stopping $(early_stopping) --group $(group) --record_loss $(record_loss) --batch_logs $(batch_logs) --lam_zero $(lam_zero) --lam_max $(lam_max) --lam_lower_bound $(lam_lower_bound) --lam_upper_bound $(lam_upper_bound)

should_transfer_files = YES
#environment = "mount=$ENV(PWD), /vol/research/NOBACKUP/CVSSP/scratch_4weeks/ad00878/DBs"
when_to_transfer_output = ON_EXIT

log = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).log
output = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).out
error = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).error


+CanCheckpoint = False
+JobRunTime = 4

request_GPUs = 1
+GPUMem = 4000
request_CPUs = 4
request_memory = 8000

#------------------------------------------
#Useful defs
#scoring_function = normal last_loss grads class_corr pred_clusters pred_biggest_move pred_best_angle
#pacing_function = none ordered mixed naieve_linear naieve_grad
#record_loss = sum = loss recorded otherwise preds recorded

#-------------------------------------------

max_epochs = 10
learning_rate = 0.001
batch_size = 32
#'random' 'last_loss' 'loss_cluster' 'loss_cluster_batches' 'pred_cluster' 'pred_euq_distance' 
#'SE_kdpp_sampling' 'submodular_sampling'
scoring_function = 'random'
#'shuffle' 'hl' 'lh' 'mixed' 'naive_linear' 'naive_grad' 'none'
pacing_function = 'shuffle'
fill_function = 'ffill'
dataset = 'mnist'
dataset_size = 1
test_dataset_size = 1
dataset_similarity = 0
data_path = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/datasets/
db_path = /vol/research/NOBACKUP/CVSSP/scratch_4weeks/ad00878/DBs/
save_model_path = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/saved_models/
early_stopping = 0
group = '0.1_mnist'
record_loss = do
batch_logs = True
lam_zero = 0
lam_max = 0
lam_lower_bound = 0
lam_upper_bound = 0

queue 3

scoring_function = 'submodular_sampling'
pacing_function = 'none'

queue 2

scoring_function = 'pred_cluster'
pacing_function = 'hl'

queue 2

scoring_function = 'loss_cluster'

queue 1

