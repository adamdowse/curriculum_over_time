#Condor submit file

universe = docker
docker_image = registry.eps.surrey.ac.uk/adamsdocker:36939

executable = /usr/bin/python3
arguments = $ENV(PWD)/RunTest.py --max_epochs $(max_epochs) --fill_function $(fill_func) --learning_rate $(lr_rate) --batch_size $(batch_size) --scoring_function $(scoring_function) --pacing_function $(pacing_function) --dataset $(dataset) --lam_zero $(lam_zero) --lam_max $(lam_max) --lam_lookback $(lam_lookback) --lam_low_first $(lam_low_first) --lam_data_multiplier $(lam_data_multiplier) --score_grav $(score_grav) --score_lookback $(score_lookback) --early_stopping $(early_stopping) --lam_lower_bound $(lam_lower_bound) --lam_upper_bound $(lam_upper_bound) 

should_transfer_files = YES
#environment = "mount=$ENV(PWD)"
when_to_transfer_output = ON_EXIT

log = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).log
output = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).out
error = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).error


+CanCheckpoint = False
+JobRunTime = 4

request_GPUs = 1
+GPUMem = 4000
request_CPUs = 4
request_memory = 4000

#set the vars and runs here

max_epochs = 50
lr_rate = 0.01
batch_size = 32
#normal, grads, class_corr, last_loss
scoring_function = class_corr
#none, ordered, naive_linear, naive_grad, stat_grad
pacing_function = ordered
#ffill, reg_fill, reg_fill_grav
fill_func = ffill
dataset = mnist
lam_zero = 0.1
lam_max = 0.9
lam_lookback = 3
lam_low_first = True
lam_data_multiplier = 10000
lam_lower_bound = $(lim)
lam_upper_bound = $(lim)
early_stopping = 20
score_grav = 0.1
score_lookback = 3

lim = -0.001

queue 1

lim = -0.01

queue 1

lim =-0.1

queue 1

lim = -1
queue 1
lim = -10
queue 1
