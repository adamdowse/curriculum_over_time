#Condor submit file

universe = docker
docker_image = registry.eps.surrey.ac.uk/adamsdocker:36939

executable = /usr/bin/python3
arguments = $ENV(PWD)/RunTest.py --max_epochs $(max_epochs) --learning_rate $(lr_rate) --batch_size $(batch_size) --scoring_function $(scoring_function) --pacing_function $(pacing_function) --dataset $(dataset) --lam_zero $(lam_zero) --lam_max $(lam_max) --lam_lookback $(lam_lookback) --lam_high_first $(lam_high_first) --lam_data_multiplier $(lam_data_multiplier) --score_grav $(score_grav) --score_lookback $(score_lookback)

should_transfer_files = YES
#environment = "mount=$ENV(PWD)"
when_to_transfer_output = ON_EXIT

log = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).log
output = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).out
error = /user/HS223/ad00878/PhD/curriculum_over_time/project/large_models/condor/c$(cluster).p$(process).error


+CanCheckpoint = False
+JobRunTime = 4

request_GPUs = 1
+GPUMem = 4000
request_CPUs = 4
request_memory = 4000

#set the vars and runs here

max_epochs = 50
lr_rate = 0.01
batch_size = 32
scoring_function = normal
pacing_function = naive_linear
dataset = mnist
lam_zero = 0.1
lam_max = 0.9
lam_lookback = 3
lam_high_first = True
lam_data_multiplier = 1
score_grav = 0.1
score_lookback = 3

queue 1


